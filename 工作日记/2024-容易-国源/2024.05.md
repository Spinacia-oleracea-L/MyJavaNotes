

# 第一周

## 5.06 周一 多云

### TODO：

1. 入职培训
2. 样本库业务流程梳理-赫测试讲解
3. 打扫通风橱

## 5.07 周二 小雨转阴

### TODO：

1. 环境部署
1. 细胞质量管理平台业务流程梳理-刁国锋讲解

## 5.08 周三 晴

### TODO：

1. 外出去拿新电脑
1. 新电脑环境部署

## 5.09 周四 晴

### TODO：

1. 项目运行，了解项目结构

1. 浙大妇产项目结构学习-刁朝阳讲解


### 收获：

* host文件配置
  ```
  127.0.0.1 biobank-register
  127.0.0.1 biobank-gateway
  127.0.0.1 biobank-redis
  10.90.12.199 biobank-mysql // 国源：浙大妇产开发库
  ```

* 微服务启动顺序

  * Nacos
  * Auth
  * Gateway
  * TxManager
  * Admin
  * 任意顺序

* 分支选择

  * dev-Phasell（二期）

* 测试账号：Spinach 密码123456

* 服务器地址：

  * http://10.90.12.192/（测试）

* 数据库

  * 浙大妇产
    * 开发：10.90.12.199
      * 用户：root
      * 密码：jyg88891715
    * 测试：10.90.12.208
      * 用户：gytest208
      * 密码：88891715

* 操作手册

## 5.10 周五 晴

### TODO：

1. bugfix:借库问题
1. 浙大妇产流程梳理
1. 本地虚拟机模拟线上环境

### 收获：

1. 虚拟机信息：

   * Hardware Address-00:0c:29:38:25:13

   * Speed-1000 Mbs

   * P Address-10.90.12.81

   * Subnet Mask-255.255.255.0

   * Default Route-10.90.12.1

   * DNS-10.90.10.124, 114.114.114.114, 223.5.5.5

2. 虚拟机用户信息

   * root
   * jyg88891715

3. 虚拟机mysql

   * 用户：root
   
   * 密码：jyg88891715
   
4. 虚拟机redis
   * 用户：auth
   * 密码：jyg88891715

## 5.11 周六 晴

### TODO：

1. 本地虚拟机模拟线上环境
1. 虚拟机模拟线上环境部署实施

# 第二周

## 5.13 周一 晴

### TODO：

1. 虚拟机模拟线上环境部署实施-解决nginx代理问题
1. 开会，了解国源生命科学（山东）集团主营业务及经营范围
1. mysql数据库自动化备份：数据在VM CentOS 7模拟
1. mysql数据库自动化备份：毓璜顶医院生产项目

### 问题：

1. 下次部署时修改hosts文件实验biobank-mysql：127.0.0.1

### 收获：

1. 国源生命科学（山东）集团
   * 主营业务：
     * **专注于生物样本库整体技术解决方案的标准化、信息化和自动化建设，是基于生物样本资源产生的技术、信息进行成果转化和技术服务的高新技术企业。**
     * **公司秉承“创新生命 服务科学”的经营理念，为用户提供专业的生物样本资源库整体设计方案、高端存储制备装备、生物样本资源库信息管理系统及生物样本资源库第三方托管服务。**
   * 自主知识产权的研发：
     * **生物样本库管理系统**
     * **细胞库管理系统**
     * **菌(毒)种保藏库信息管理系统**
     * **样本库物资/资产管理系统**
     * **样本库及实验室环境监测系统**
     * **物联网设备云平台**
   * 支持国家人类遗传资源中心建设，在全国以区域创新中心的形式对人类遗传资源进行收集、存储。

2. 国源生命科学（山东）集团

   * 开发部版本

     * > 1.专注于生物样本库整体技术解决方案的标准化、信息化和自动化建设，为用户提供专业的生物样本资源库整体设计方案、高端存储制备装备、生物样本资源库信息管理系统及生物
       > 样本资源库第三方托管服务。
       > 2.以及面向于疾控、科研等领域，我们可以提供细胞质量管理平台、菌毒种样本管理平台、实验室物料耗材管理平台、环境监控平台的信息化以及自动化建设。
       > 3.承担客户质量管理体系的搭建工作，协助客户获得人类遗传资源行政审批批件，确保生物样本库更加合规、高效的运行。
       > 4.如问到七大产品或者几大产品的话，产品为：样本库信息管理平台、细胞质量管理平台、菌毒种样本管理平台、实验室物料耗材管理平台、环境监控平台、资产管理平台、档案管理平台、设备管理平台。
       > 简称为：样本库、细胞、菌毒种（疾控）、实验室物料、环境监控、资产、档案、设备平台

3. mysql数据库自动化备份：数据在VM CentOS 7

  ```shell
    #Mysql dabase information
    #主机
    db_host="localhost"
    #数据库帐号
    db_user="root"
    #数据库密码
    db_passwd="jyg88891715"
    #mysql安装目录
    MYSQL="/usr/local/mysql/mysql8"
    #mysql命令目录
    MYSQLDUMP="/usr/local/mysql/mysql8/bin/mysqldump"
    
    
    
    
    #Path information
    #存放备份文件的路径
    BACKUP_DB="/opt/backup/database"
    LogFile=$BACKUP_DB"/bak.log"
    
    
    #Time information
    #时间
    time=`date +"%Y-%m-%d-%H-%M-%S"`
    day=`date +"%d"`
    month=`date +"%Y-%m"`
    weekday=`date +"%u"`
    
    
    
    
    
    
    #Path enable write
    if [ ! -w "$BACKUP_DB" ]; then
        mkdir -p "$BACKUP_DB"
        chmod -R 700 $BACKUP_DB
    fi
    
    
    #echo "**********************************host info****************************************"
    #echo "db_host:"$db_host
    #echo "db_user:"$db_user
    #echo "db_passwd:"$db_passwd
    #echo "MYSQL:"$MYSQL
    #echo "MYSQLDUMP:"$MYSQLDUMP
    #echo "databaseName:"$databaseName
    #echo "BACKUP_DB:"$BACKUP_DB
    #echo "**********************************************************************************"
    
    
    
    
    #Mysql Backup
    Date=`date +%Y%m%d`
    Begin=`date +"%Y-%m-%d %H:%M:%S"`
    #echo "start backup database:"$databaseName"   "$Begin
    
    
    #databases
    #需要备份的数据库，如果有多个数据库，请用,分隔
    databaseList="hzfck_biobankx,hzfck_biobankx_ac,hzfck_biobankx_config,hzfck_biobankx_job,hzfck_biobankx_platform"
    for databaseName in `echo "$databaseList" | sed 's/,/\n/g'`
    do  
        echo $databaseName
    
    
    #fileName
    #生成备份文件名
    fileName=$databaseName"-"$time".sql"
    #生成备份文件完整路径
    BACKUP_DBPATH=$BACKUP_DB"/"$databaseName
    
    
    
    
    #echo "***********************************database Info***********************************************"
    #echo "BACKUP_DBPATH:"$BACKUP_DBPATH
    #echo "fileName:"$fileName
    #echo "**********************************************************************************"
    
    
     
    
    
    if [ ! -d "$BACKUP_DBPATH" ]; then
        mkdir -p "$BACKUP_DBPATH" 
    fi
    #备份mysql
    $MYSQLDUMP -u $db_user -p$db_passwd -h $db_host $databaseName > $BACKUP_DBPATH/$fileName
    #打包.sql文件
    cd $BACKUP_DBPATH && tar -czf $fileName.tar.gz $fileName && rm -rf $fileName && chmod go-rwx $fileName.tar.gz
    
    
    Last=`date +"%Y-%m-%d %H:%M:%S"`
    #echo "end backup database:"$databaseName"   "$Last
    #输出日志
    echo start:$Begin end:$Last $fileName succ >> $LogFile
    done
  ```

3. **脚本文件授权**

  ```shell
  cd /opt/shell-file/mysql-backup.sh
  chmod +x mysql-backup.sh
  ```

4. 立即执行脚本-测试

  ```shell
  sh mysql-backup.sh
  ```

4. **cron表达式参考**

  ```shell
  0 * * * * /opt/shell-file/mysql-backup.sh # Cron 就会每小时执行一次 mysql-backup.sh 脚本
  * * * * * /opt/shell-file/mysql-backup.sh # Cron 就会每分钟执行一次 mysql-backup.sh 脚本
  0 1 * * * /opt/shell-file/mysql-backup.sh # Cron 就会在每天凌晨1点（即0小时0分）执行位于 /opt/shell-file/mysql-backup.sh 脚本
  ```

​	ps：注意：**最后一个cron表达式需要有空格**

​	出现提示：crontab: installing new crontab

5. **使用cronbat执行脚本**

  ```shell
  # 运行,使用vim编辑
  crontab -e
  # 设置脚本执行周期
  0 1 * * * /opt/shell-file/mysql-backup.sh
  # 查询任务是否设置成功
  crontab -l
  # 重启crontab
  service crond restart
  ```

ps：毓璜顶医院sql 备份

```shell
#Mysql dabase information
#主机
db_host="localhost"
#数据库帐号
db_user="root"
#数据库密码
db_passwd="jyg88891715"
#mysql安装目录
MYSQL="/usr/local/mysql8"
#mysql命令目录
MYSQLDUMP="/usr/local/mysql8/bin/mysqldump"




#Path information
#存放备份文件的路径
BACKUP_DB="/Lenovonfs/mysqlbak"
LogFile=$BACKUP_DB"/bak.log"


#Time information
#时间
time=`date +"%Y-%m-%d-%H-%M-%S"`
day=`date +"%d"`
month=`date +"%Y-%m"`
weekday=`date +"%u"`






#Path enable write
if [ ! -w "$BACKUP_DB" ]; then
    mkdir -p "$BACKUP_DB"
    chmod -R 700 $BACKUP_DB
fi


#echo "**********************************host info****************************************"
#echo "db_host:"$db_host
#echo "db_user:"$db_user
#echo "db_passwd:"$db_passwd
#echo "MYSQL:"$MYSQL
#echo "MYSQLDUMP:"$MYSQLDUMP
#echo "databaseName:"$databaseName
#echo "BACKUP_DB:"$BACKUP_DB
#echo "**********************************************************************************"




#Mysql Backup
Date=`date +%Y%m%d`
Begin=`date +"%Y-%m-%d %H:%M:%S"`
#echo "start backup database:"$databaseName"   "$Begin


#databases
#需要备份的数据库，如果有多个数据库，请用,分隔
databaseList="ytyhd_biobankx,ytyhd_biobankx_ac,ytyhd_biobankx_config,ytyhd_biobankx_job,ytyhd_biobankx_platform"
for databaseName in `echo "$databaseList" | sed 's/,/\n/g'`
do  
    echo $databaseName


#fileName
#生成备份文件名
fileName=$databaseName"-"$time".sql"
#生成备份文件完整路径
BACKUP_DBPATH=$BACKUP_DB"/"$databaseName




#echo "***********************************database Info***********************************************"
#echo "BACKUP_DBPATH:"$BACKUP_DBPATH
#echo "fileName:"$fileName
#echo "**********************************************************************************"


 


if [ ! -d "$BACKUP_DBPATH" ]; then
    mkdir -p "$BACKUP_DBPATH" 
fi
#备份mysql
$MYSQLDUMP -u $db_user -p$db_passwd -h $db_host $databaseName > $BACKUP_DBPATH/$fileName
#打包.sql文件
cd $BACKUP_DBPATH && tar -czf $fileName.tar.gz $fileName && rm -rf $fileName && chmod go-rwx $fileName.tar.gz


Last=`date +"%Y-%m-%d %H:%M:%S"`
#echo "end backup database:"$databaseName"   "$Last
#输出日志
echo start:$Begin end:$Last $fileName succ >> $LogFile
done

```

## 5.14 周二 晴

### TODO：

1. 毓璜顶线上数据库自动备份，验证
1. 毓璜顶线上数据库自动备份重部署
1. 杭州妇产-登记管理-信息登记-体液扫描（2小时内重复扫描弹窗）测试
1. 杭州妇产-Quartz管理-MOCK手术排班数据的自动任务-重写RandomValue类取代线上mock-min.js

### 收获：

1. 在 Linux 中配置 crontab，如果有多个表达式，只需要在最后一个 cron 指令后面加空格即可。

   > 例如，以下 crontab 配置文件包含两个 cron 指令：
   >
   > ```shell
   > 0 1 * * *  /bin/task1
   > 0 2 * * *  /bin/task2
   > ```
   >
   > 第一个 cron 指令表示每天凌晨1点执行 `/bin/task1` 任务，第二个 cron 指令表示每天凌晨2点执行 `/bin/task2` 任务。
   >
   > 需要注意的是，如果最后一个 cron 指令后面没有空格，则会报错。例如，以下 crontab 配置文件会报错：
   >
   > ```shell
   > 0 1 * * *  /bin/task1
   > 0 2 * * *  /bin/task2
   > ```
   >
   > 因为 crontab 解析器会将 `/bin/task2` 视为第一个 cron 指令的一部分，导致语法错误。
   >
   > 参考资料
   >
   > * https://www.baeldung.com/linux/crontab
   > * https://crontab.guru/

2. Linux的crontab配置文件在*/etc/crontab*中

   ```shell
   SHELL=/bin/bash
   PATH=/sbin:/bin:/usr/sbin:/usr/bin
   MAILTO=root
   
   # For details see man 4 crontabs
   
   # Example of job definition:
   # .---------------- minute (0 - 59)
   # |  .------------- hour (0 - 23)
   # |  |  .---------- day of month (1 - 31)
   # |  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ...
   # |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat
   # |  |  |  |  |
   # *  *  *  *  * user-name  command to be executed
   ```

   3.杭州妇产登录账号
   
   * Spinach 123456
   * SWYBK1 123456
   * admin_hzfck 123456

## 5.15 周三 晚上大风转晴

### TODO：

1. 范总开会，制度强调，公司业务检查
1. 杭州妇产样本库流程熟悉

### 问题：

1. 工单管理-当日工单监控-【手术开始】状态弹窗提示
2. 菜单查看权限

### 收获：

1.  **住院医生工作站--生物样本库医嘱管理**
   * api接口：localhost:8080/#/checkdoctor?applyEmpno=6532&applyBy=蒋桂英&applySection=妇产外科%28湖滨院区%29&applySectionCode=HBWK&patientId=0515-96223&patientUid=0515-96223-99&patType=ZY&hosId=H001
   * 说明：大部分信息可以在-工单管理中的-查看信息中的F12中的信息内查看；但是部分医院信息、医生信息需要在mock_emp_info，mock_dept_info内联合查看
     * applyEmpno---mock_emp_info中的empid
     * applyBy---mock_emp_info中的empname
     * applySection---mock_emp_info中的deptname
     * applySectionCode---mock_emp_info中的deptid
     * patientId---病例信息-patientId
     * patientUid---病例信息-patientUid
     * patType---病例信息-patientType
     * hosId---mock_dept_info中的hosid
2. **护士工作站--生物样本库医嘱管理**
   * api接口：localhost:8080/#/checknurse
   * 说明：可以直接登录，账号可在mock_emp_info中查看

## 5.16 周四 晴

### TODO：

1. 发现妇产bug，登记管理-信息登记-样本输入时，捐献者信息DonorInfoServiceImpl。已解决登录权限问题
2. 台州医院，线上运维，数据库修改
3. 发现妇产bug，登记管理-同源样本-调整存储位置时
4. 下班后部署-邵逸夫线上生产

### 收获：

1. 毓璜顶和邵逸夫打包时需要切换prod配置文件
2. 台州和杭州妇产打包时默认dev配置文件

## 5.17 周五 晴

### TODO：

1. 登记管理-同源样本-调整存储位置时，解决问题，开发库中少一张表
1. 杭州妇产主要流程熟悉完毕

## 5.18 周六 晴

### TODO：

1. 杭州妇产独立分支功能流程熟悉
1. 工作会议，汇报一周工作成果

# 第三周

## 5.20 周一 阴（周天冰雹今天凉爽）

### TODO：

1. 发现bug-资产管理-仪器设备信息管理-sql报错。已解决数据库少字段

   * ```shell
     ### Error querying database.  Cause: java.sql.SQLSyntaxErrorException: Unknown column 'connect_url' in 'field list'
     ### The error may exist in file [D:\ProgramData\IdeaProjects\guoyuan\2024\杭州妇产科医院生物样本库\biobank-platform\biobank-master\biobank-master-biz\target\classes\mapper\asset\InstMapper.xml]
     ### The error may involve defaultParameterMap
     ### The error occurred while setting parameters
     ### SQL: SELECT `id`, `supplier_id`, `oem_id`, `inst_type_id`, `inst_model`, `inst_no`, `inst_name`, `dept_id`, `inst_use`, `amount`, `address`, `buy_time`, `use_time`, `inst_status`, `service_life`, `connect_status`, connect_url, `remark`, `create_by`, `create_time`, `update_by`, `update_time`, `del_flag`, `district_id` FROM `asset_inst` WHERE `del_flag` = ? ORDER BY `buy_time` DESC LIMIT ?,?
     ### Cause: java.sql.SQLSyntaxErrorException: Unknown column 'connect_url' in 'field list'
     ```

2. 禅道-9100 台州项目-深低温存储管理-设备操作单分页查询中的操作列添加手动结束按钮，用于将异常结束的操作单手动结束

### 收获：

1. 台州项目
   * 账号：admin_tz 123456

2. ```shell
   ### maven验证、打包时报错，
   ### [ERROR] Failed to execute goal org.apache.maven.plugins:maven-resources-plugin:3.3.1:resources (default-resources) on project biobank-register: filtering D:\ProgramData\IdeaProjects\guoyuan\2024\台州医院生物样本库\biobank-register\src\main\resources\static\console-fe\public\css\fonts\aliyun-console-font.eot to D:\ProgramData\IdeaProjects\guoyuan\2024\台州医院生物样本库\biobank-register\target\classes\static\console-fe\public\css\fonts\aliyun-console-font.eot failed with MalformedInputException: Input length = 1 -> [Help 1] 
   ```

   这个错误信息表明在Maven构建项目时，`maven-resources-plugin`插件在处理资源文件时遇到了编码问题。具体来说，`aliyun-console-font.eot`文件在过滤过程中发生了`MalformedInputException: Input length = 1`错误。

   这是因为资源文件在被复制或处理时，Maven默认尝试对其进行过滤（例如替换变量），但某些文件（如字体文件、图片等二进制文件）不适合进行文本过滤。

   ### 解决办法
   为了避免这种问题，可以配置Maven资源插件忽略对这些二进制文件的过滤。你可以在`pom.xml`文件中进行如下配置：

   1. 打开你的`pom.xml`文件。
   2. 找到或添加`maven-resources-plugin`的配置部分。
   3. 在配置中指定需要排除过滤的文件。

   示例配置如下：

   ```xml
   <build>
       <plugins>
           <plugin>
               <groupId>org.apache.maven.plugins</groupId>
               <artifactId>maven-resources-plugin</artifactId>
               <version>3.3.1</version>
               <executions>
                   <execution>
                       <id>default-resources</id>
                       <phase>process-resources</phase>
                       <goals>
                           <goal>resources</goal>
                       </goals>
                       <configuration>
                           <encoding>UTF-8</encoding>
                           <nonFilteredFileExtensions>
                               <nonFilteredFileExtension>eot</nonFilteredFileExtension>
                               <nonFilteredFileExtension>woff</nonFilteredFileExtension>
                               <nonFilteredFileExtension>ttf</nonFilteredFileExtension>
                               <nonFilteredFileExtension>svg</nonFilteredFileExtension>
                               <nonFilteredFileExtension>otf</nonFilteredFileExtension>
                               <nonFilteredFileExtension>png</nonFilteredFileExtension>
                               <nonFilteredFileExtension>jpg</nonFilteredFileExtension>
                               <nonFilteredFileExtension>gif</nonFilteredFileExtension>
                           </nonFilteredFileExtensions>
                       </configuration>
                   </execution>
               </executions>
           </plugin>
       </plugins>
   </build>
   ```

   这个配置告诉`maven-resources-plugin`在处理资源文件时，不对`.eot`、`.woff`、`.ttf`、`.svg`、`.otf`、`.png`、`.jpg`和`.gif`文件进行过滤。这应该可以避免你遇到的编码问题。

   保存`pom.xml`文件后，重新运行Maven构建命令：

   ```sh
   mvn clean package
   ```

   这样应该可以解决问题。如果问题依然存在，请检查文件路径和文件名是否正确，并确保所有需要排除的文件类型都已在配置中列出。

### 问题：

1. 工单管理-确认工单

| id   | select_type | table                  | partitions | type | possible_keys | key         | key_len | ref  | rows | filtered | Extra                                              |
| ---- | ----------- | ---------------------- | ---------- | ---- | ------------- | ----------- | ------- | ---- | ---- | -------- | -------------------------------------------------- |
| 1    | PRIMARY     | t1                     |            | ALL  |               |             |         |      | 2533 | 100      |                                                    |
| 1    | PRIMARY     | t2                     |            | ALL  |               |             |         |      | 137  | 100      | Using where; Using join buffer (Block Nested Loop) |
| 1    | PRIMARY     | <derived2>             |            | ref  | <auto_key0>   | <auto_key0> | 131     | func | 10   | 100      | Using where                                        |
| 1    | PRIMARY     | <derived3>             |            | ALL  |               |             |         |      | 333  | 100      | Using where; Using join buffer (Block Nested Loop) |
| 1    | PRIMARY     | <derived4>             |            | ALL  |               |             |         |      | 1    | 100      | Using where; Using join buffer (Block Nested Loop) |
| 4    | DERIVED     | surgical_advice_record |            | ALL  |               |             |         |      | 1666 | 100      |                                                    |
| 3    | DERIVED     | t2                     |            | ALL  |               |             |         |      | 1666 | 20       | Using where; Using temporary                       |
| 2    | DERIVED     | surgical_advice_record |            | ALL  |               |             |         |      | 1666 | 10       | Using where; Using temporary                       |

```sql
EXPLAIN
SELECT
	t1.id,
	t1.district_id AS districtId,
	t1.patient_uid AS patientUid,
	t1.patient_id AS patientId,
	t1.patient_type AS patientType,
	t1.pat_name AS patName,
	t1.pat_bed AS patBed,
	t1.pat_sex AS patSex,
	t1.pat_age AS patAge,
	t1.oper_no AS operNo,
	t1.is_deleted AS isDeleted,
	t1.schel_no AS schelNo,
	t1.oper_type AS operType,
	t1.mian_opername AS mianOpername,
	t1.first_opername AS firstOpername,
	t1.secd_opername AS secdOpername,
	t1.dignose AS dignose,
	t1.notch_type AS notchType,
	t1.ane_tyoe AS aneTyoe,
	t1.apply_doc AS applyDoc,
	t1.oper_doc AS operDoc,
	t1.hiv AS hiv,
	t1.hbsage AS hbsage,
	t1.apply_dept AS applyDept,
	t1.oper_date AS operDate,
	t1.plan_time AS planTime,
	t1.set_no AS setNo,
	t1.room_no AS roomNo,
	t1.state AS state,
	t1.order_flag AS orderFlag,
	t1.rpr AS rpr,
	t1.dept_id,
	t1.create_time AS createTime,
	t1.delete_reason AS deleteReason,
	t1.apply_dept_code AS applyDeptCode,
	IFNULL( t2.special_focus, 'N' ) AS specialFocus,
	t2.no_reason AS noReason,
	t2.tag_type AS tagType,
	t5.remark AS remark,
	IFNULL( t3.advTotal, 0 ) AS advTotal,
	IFNULL( t4.advNum, 0 ) AS advNum,
	t3.close_reason AS closeReason 
FROM
	`surgical_schedule_list` t1
	LEFT JOIN surgical_schedule_remark t2 ON t1.id = t2.surgical_id
	LEFT JOIN ( SELECT schedule_id, COUNT( 1 ) AS advTotal, close_reason FROM surgical_advice_record WHERE del_flag = 0 GROUP BY schedule_id ) t3 ON t3.schedule_id = t1.id
	LEFT JOIN ( SELECT schedule_id, COUNT( 1 ) AS advNum FROM surgical_advice_record t2 WHERE t2.adv_state IN ( 3, 4 ) GROUP BY schedule_id ) t4 ON t1.id = t4.schedule_id
	LEFT JOIN ( SELECT schedule_id, GROUP_CONCAT( DISTINCT remark ) AS remark FROM `surgical_advice_record` ) t5 ON t5.schedule_id = t1.id
```

**优化建议**

根据你提供的 `explain` 结果和 SQL 语句，可以进行以下优化：

1. **添加索引:**

* 在 `surgical_schedule_list` 表上添加索引，包括以下列：
    * `patient_id`
    * `oper_doc`
    * `oper_date`
    * `order_flag`
    * `delete_reason`
    * `no_reason`
    * `district_id`
* 在 `surgical_schedule_remark` 表上添加索引，包括以下列：
    * `surgical_id`
    * `no_reason`
    * `tag_type`
* 在 `surgical_advice_record` 表上添加索引，包括以下列：
    * `schedule_id`
    * `adv_state`
    * `del_flag`

2. **优化子查询:**

* 将子查询 `t3` 和 `t4` 优化为 JOIN 语句，以减少嵌套查询的开销。

3. **避免使用 `GROUP_CONCAT` 函数:**

* 如果 `remark` 列不需要在结果中显示，可以将其从 `SELECT` 语句中删除。
* 如果需要在结果中显示 `remark` 列，可以考虑使用其他方法，例如将 `remark` 列存储在单独的表中，并使用 JOIN 语句进行关联。

4. **使用覆盖索引:**

* 如果查询只需要返回部分列，可以考虑使用覆盖索引，以减少数据读取的开销。

5. **调整 `explain` 语句:**

* 你可以使用 `explain extended` 语句获取更详细的执行计划，以便更好地分析查询的性能瓶颈。

**优化后的 SQL 语句**

```sql
/* 添加索引 */
CREATE INDEX idx_surgical_schedule_list_patient_id ON surgical_schedule_list(patient_id);
CREATE INDEX idx_surgical_schedule_list_oper_doc ON surgical_schedule_list(oper_doc);
CREATE INDEX idx_surgical_schedule_list_oper_date ON surgical_schedule_list(oper_date);
CREATE INDEX idx_surgical_schedule_list_order_flag ON surgical_schedule_list(order_flag);
CREATE INDEX idx_surgical_schedule_list_delete_reason ON surgical_schedule_list(delete_reason);
CREATE INDEX idx_surgical_schedule_list_no_reason ON surgical_schedule_list(no_reason);
CREATE INDEX idx_surgical_schedule_list_district_id ON surgical_schedule_list(district_id);
CREATE INDEX idx_surgical_schedule_remark_surgical_id ON surgical_schedule_remark(surgical_id);
CREATE INDEX idx_surgical_schedule_remark_no_reason ON surgical_schedule_remark(no_reason);
CREATE INDEX idx_surgical_schedule_remark_tag_type ON surgical_schedule_remark(tag_type);
CREATE INDEX idx_surgical_advice_record_schedule_id ON surgical_advice_record(schedule_id);
CREATE INDEX idx_surgical_advice_record_adv_state ON surgical_advice_record(adv_state);
CREATE INDEX idx_surgical_advice_record_del_flag ON surgical_advice_record(del_flag);

/* 优化后的 SQL 语句 */
SELECT
  t1.id,
  t1.district_id AS districtId,
  t1.patient_uid AS patientUid,
  t1.patient_id AS patientId,
  t1.patient_type AS patientType,
  t1.pat_name AS patName,
  t1.pat_bed AS patBed,
  t1.pat_sex AS patSex,
  t1.pat_age AS patAge,
  t1.oper_no AS operNo,
  t1.is_deleted AS isDeleted,
  t1.schel_no AS schelNo,
  t1.oper_type AS operType,
  t1.mian_opername AS mianOpername,
  t1.first_opername AS firstOpername,
  t1.secd_opername AS secdOpername,
  t1.dignose AS dignose,
  t1.notch_type AS notchType,
  t1.ane_tyoe AS aneTyoe,
  t1.apply_doc AS applyDoc,
  t1.oper_doc AS operDoc,
  t1.hiv AS hiv,
  t1.hbsage AS hbsage,
  t1.apply_dept AS applyDept,
  t1.oper_date AS operDate,
  t1.plan_time AS planTime,
  t1.set_no AS setNo,
  t1.room_no AS roomNo,
  t1.state AS state,
  t1.order_flag AS orderFlag,
  t1.rpr AS rpr,
  t1.dept_id,
  t1.create_time AS createTime,
  t1.delete_reason AS deleteReason,
  t1.apply_dept_code AS applyDeptCode,
  IFNULL(t2.special_focus, 'N') AS specialFocus,
  t2.no_reason AS noReason,
  t2.tag_type AS tagType,
  t3.advTotal,
  t3.close_reason,
  t4.advNum
FROM
  surgical_schedule_list t1
LEFT JOIN surgical_schedule_remark t2 ON t1.id = t2.surgical_id
LEFT JOIN (
  SELECT
    schedule_id,
    COUNT(1) AS advTotal,
    close_reason
  FROM surgical_advice_record
  WHERE del_flag = 0
  GROUP BY
    schedule_id
) t3 ON t3.schedule_id = t1.id
LEFT JOIN (
  SELECT
    schedule_id,
    COUNT(1) AS advNum
  FROM surgical_advice_record
  WHERE adv_state IN (3, 4)
  GROUP BY
    schedule_id
) t4 ON t1.id = t4.schedule_id;
```

**注意事项**

* 优化建议仅供参考，实际效果可能因数据量和硬件环境等因素而有所不同。
* 建议在优化之前进行基准测试，以便评估优化后的效果。
* 优化过程中需要注意数据的一致性和完整性。

## 5.21 周二 晴

### TODO：

1. 杭州妇产项目-进行系统优化-初步开始sql查询优化
1. 禅道-9103 毓璜顶医院-异地备份的数据库文件添加定时删除，保留6天的数据

### 收获：

1. 清理脚本VM CentOS 7

   * ```shell
     #删除七天前备份，也就是只保存7天内的备份
     #-mtime、-ctime、-atime 修改时间、状态时间、存取时间
     
     #-mtime n 查找修改时间前24*n小时内的文件			24*n<mtime<24*(n+1)
     #-mtime +n 查找修改时间超过24*(n+1)小时的文件		mtime>24*(n+1)
     #-mtime -n 查找修改时间不超过24*n小时的文件		mtime<24*n
     
     #-mmin n 查找修改时间前n分钟内的数据(参数同-mtime)
     ```

   * ```shell
     #!/bin/bash
     
     #存放备份文件的路径
     BACKUP_DB="/opt/backup/database"
     LogFile=$BACKUP_DB"/clean.log"
     
     #Time information
     Begin=`date +"%Y-%m-%d %H:%M:%S"`
     
     # Find and delete backup files older than 6 days
     find $BACKUP_DB -type f -name "*.tar.gz" -mtime +6 -exec rm -f {} \;
     
     Last=`date +"%Y-%m-%d %H:%M:%S"`
     
     # Log cleanup
     echo start:$Begin end:$Last "cleanup old backups" >> $LogFile
     ```

   * `find $BACKUP_DB -type f -name "*.tar.gz" -mtime +6 -exec rm -f {} \;`

   * - `find $BACKUP_DB`: 查找`$BACKUP_DB`目录下的文件。
     - `-type f`: 只查找文件。
     - `-name "*.tar.gz"`: 匹配以`.tar.gz`结尾的文件，即备份文件。
     - `-mtime +6`: 查找修改时间在6天之前的文件。
     - `-exec rm -f {} \;`: 删除找到的文件。

2. **脚本文件授权**

   * ```shell
     cd /opt/shell-file/clean_backup.sh
     chmod +x clean_backup.sh
     ```

3. 添加到Crontab

   * 可以将这个清理脚本添加到crontab中，确保它每天运行一次，以便定期清理旧的备份文件。例如，可以将以下行添加到crontab中：

     ```shell
     0 2 * * * /path/to/clean_backup.sh
     ```

     这将每天凌晨2点执行清理脚本，删除6天之前的备份文件。确保将清理脚本的路径替换为实际的路径。

4. **合并到现有备份脚本中**

   如果你希望在备份脚本中添加清理逻辑，可以将清理代码直接添加到备份脚本的末尾：

   ```shell
   # Backup script content...
   
   # Mysql Backup
   Date=`date +%Y%m%d`
   Begin=`date +"%Y-%m-%d %H:%M:%S"`
   #echo "start backup database:"$databaseName"   "$Begin
   
   #databases
   databaseList="hzfck_biobankx,hzfck_biobankx_ac,hzfck_biobankx_config,hzfck_biobankx_job,hzfck_biobankx_platform"
   for databaseName in `echo "$databaseList" | sed 's/,/\n/g'`
   do  
       echo $databaseName
   
       fileName=$databaseName"-"$time".sql"
       BACKUP_DBPATH=$BACKUP_DB"/"$databaseName
   
       if [ ! -d "$BACKUP_DBPATH" ]; then
           mkdir -p "$BACKUP_DBPATH" 
       fi
       $MYSQLDUMP -u $db_user -p$db_passwd -h $db_host $databaseName > $BACKUP_DBPATH/$fileName
       cd $BACKUP_DBPATH && tar -czf $fileName.tar.gz $fileName && rm -rf $fileName && chmod go-rwx $fileName.tar.gz
   
       Last=`date +"%Y-%m-%d %H:%M:%S"`
       echo start:$Begin end:$Last $fileName succ >> $LogFile
   done
   
   # Cleanup old backups
   Begin=`date +"%Y-%m-%d %H:%M:%S"`
   find $BACKUP_DB -type f -name "*.tar.gz" -mtime +6 -exec rm -f {} \;
   Last=`date +"%Y-%m-%d %H:%M:%S"`
   echo start:$Begin end:$Last "cleanup old backups" >> $LogFile
   ```

   这样就可以在每次备份完成后立即清理旧的备份文件。

5. 毓璜顶医院清理脚本

   * ```shell
     #!/bin/bash
     
     #存放备份文件的路径
     BACKUP_DB="/Lenovonfs/mysqlbak"
     LogFile=$BACKUP_DB"/clean.log"
     
     # 脚本开始时间
     Begin=`date +"%Y-%m-%d %H:%M:%S"`
     
     #-mtime n 查找修改时间前24*n小时内的文件			24*n<mtime<24*(n+1)
     #-mtime +n 查找修改时间超过24*(n+1)小时的文件		mtime>24*(n+1)
     #-mtime -n 查找修改时间不超过24*n小时的文件		mtime<24*n
     
     # 找到并删除超过六天的老备份文件
     find $BACKUP_DB -type f -name "*.tar.gz" -mtime +6 -exec rm -f {} \;
     
     # 脚本结束时间
     Last=`date +"%Y-%m-%d %H:%M:%S"`
     
     # 日志输出
     echo start:$Begin end:$Last "cleanup old backups" >> $LogFile
     ```

6. Linux执行脚本命令时提示$'\r': command not found错误的解决方法

   * 现象：写的bash脚本，运行时报$'\r': command not found错误。
   * 原因：windows和Linux的换行符不同(windows是\r\n,而Linux是\n)导致的
   * 解决办法：
     * \# vi filename
     * 命令行模式下,输入---->:set ff=unix
     * 将换行符设置成UNIX的模式

## 5.22 周三 晴

### TODO：

1. 验证毓璜顶-异地备份的数据库文件添加定时删除
1. 台州医院-院内接口验证调试
1. 台州医院-质控管理-质控计划管理-数据回传-多模板问题

## 5.23 周四 晴

### TODO：

1. 禅道-9126 样本库系统-在存储管理/入库申请单，点入库后添加一个“扫盒入库”入库功能

## 5.24 周五 阴（凉快）

### TODO：

1. 邵逸夫线上存储管理-样本检索-制备时间问题跟进
1. 台州院内患者知情同意书接口-返回数据结构变化-修改原本调用逻辑

## 5.25 周六 多云

### TODO：

1. 工作总结汇报会
1. 邵逸夫系统升级

### 收获：

1. 邵逸夫庆春：
   * 账号：75071
   * 密码：000000
2. 邵逸夫下沙：
   * 账号：85049
   * 密码：000000
3. 邵逸夫更新完毕后，需要清理redis缓存

# 第四周

## 5.27 周一 晴

### TODO：

1. VM CentOs 7模拟磁盘新增挂载和扩容
2. 禅道-9139 服务器磁盘扩容-将服务器上扩容的空间挂载到199服务器的根目录下
3. 刁朝阳-邵逸夫任务登记管理-校验管理-校验逻辑-交接

### 收获：

1. Linux新增磁盘

   * ```shell
     fdisk -l # 查看当前的磁盘状态
     ```


   * ```bash
     root@localhost ~]# fdisk -l
     
     Disk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectors
     Units = sectors of 1 * 512 = 512 bytes
     Sector size (logical/physical): 512 bytes / 512 bytes
     I/O size (minimum/optimal): 512 bytes / 512 bytes
     
     
     Disk /dev/sda: 21.5 GB, 21474836480 bytes, 41943040 sectors
     Units = sectors of 1 * 512 = 512 bytes
     Sector size (logical/physical): 512 bytes / 512 bytes
     I/O size (minimum/optimal): 512 bytes / 512 bytes
     Disk label type: dos
     Disk identifier: 0x000ad384
     
        Device Boot      Start         End      Blocks   Id  System
     /dev/sda1   *        2048     2099199     1048576   83  Linux
     /dev/sda2         2099200    41943039    19921920   8e  Linux LVM
     
     Disk /dev/mapper/centos-root: 18.2 GB, 18249416704 bytes, 35643392 sectors
     Units = sectors of 1 * 512 = 512 bytes
     Sector size (logical/physical): 512 bytes / 512 bytes
     I/O size (minimum/optimal): 512 bytes / 512 bytes
     
     
     Disk /dev/mapper/centos-swap: 2147 MB, 2147483648 bytes, 4194304 sectors
     Units = sectors of 1 * 512 = 512 bytes
     Sector size (logical/physical): 512 bytes / 512 bytes
     I/O size (minimum/optimal): 512 bytes / 512 bytes
     ```

     > - ## `fdisk -l` 命令输出的中文解析：
     >
     >   这个命令显示了连接到您系统上的磁盘信息。以下是输出的解释：
     >
     >   **磁盘 /dev/sdb：**
     >
     >   * **大小：** 21.5 GB
     >   * **总扇区数：** 41943040
     >   * **单位：** 每扇区 512 字节
     >   * **扇区大小：** 512 字节
     >   * **I/O 大小：** 512 字节
     >
     >   **磁盘 /dev/sda：**
     >
     >   * **大小：** 21.5 GB
     >   * **总扇区数：** 41943040
     >   * **单位：** 每扇区 512 字节
     >   * **扇区大小：** 512 字节
     >   * **I/O 大小：** 512 字节
     >   * **磁盘标签类型：** dos
     >   * **磁盘标识符：** 0x000ad384
     >   * **分区：**
     >       * **`/dev/sda1`：**
     >           * 启动标志：`*`（活动）
     >           * 起始扇区：2048
     >           * 结束扇区：2099199
     >           * 大小：1048576 扇区
     >           * ID：83（Linux）
     >           * 系统：Linux
     >       * **`/dev/sda2`：**
     >           * 起始扇区：2099200
     >           * 结束扇区：41943039
     >           * 大小：19921920 扇区
     >           * ID：8e（Linux LVM）
     >           * 系统：Linux LVM
     >
     >   **磁盘 /dev/mapper/centos-root：**
     >
     >   * **大小：** 18.2 GB
     >   * **总扇区数：** 35643392
     >   * **单位：** 每扇区 512 字节
     >   * **扇区大小：** 512 字节
     >   * **I/O 大小：** 512 字节
     >
     >   **磁盘 /dev/mapper/centos-swap：**
     >
     >   * **大小：** 2147 MB
     >   * **总扇区数：** 4194304
     >   * **单位：** 每扇区 512 字节
     >   * **扇区大小：** 512 字节
     >   * **I/O 大小：** 512 字节
     >
     >   **其他信息：**
     >
     >   * 输出还提到您在 `/var/spool/mail/root` 中有新邮件。
     >
     >   ## 用更简单的语言解释：
     >
     >   您的系统有两个物理磁盘：`/dev/sdb` 和 `/dev/sda`。第一个磁盘没有分区，而第二个磁盘有两个分区：`/dev/sda1` 和 `/dev/sda2`。第一个分区是 Linux 分区，而第二个分区是 Linux LVM 分区。
     >
     >   系统还创建了两个逻辑卷：`/dev/mapper/centos-root` 和 `/dev/mapper/centos-swap`。第一个逻辑卷用作根文件系统，而第二个逻辑卷用作交换空间。
     >

   * 将未分区的 `/dev/sdb` 初始化为可用状态：

     1. 使用 `fdisk` 命令进行分区：

        ```bash
        fdisk /dev/sdb
        ```

        * 输入 `m` 命令查看帮助菜单。
        * 输入 `n` 命令创建新分区。
        * 选择分区类型（例如，`p` 表示主分区）。
        * 输入分区编号（例如，1）。
        * 输入起始扇区和结束扇区（默认值通常可以接受）。
        * 输入 `t` 命令更改分区类型。
        * 输入分区编号。
        * 输入分区类型代码（例如，`83` 表示 Linux）。
        * 输入 `w` 命令保存更改并退出 `fdisk`。

     2. 格式化分区：

        ```bash
        mkfs.ext4 /dev/sdb1  # 替换为实际的分区名称
        ```

        * 您可以使用其他文件系统类型，例如 `xfs` 或 `ntfs`。

     3. 挂载分区：

        ```bash
        mkdir /mnt/sdb1  # 创建挂载点
        mount /dev/sdb1 /mnt/sdb1  # 挂载分区
        ```

     4. 设置自动挂载：

        ```bash
        echo "/dev/sdb1 /mnt/sdb1 ext4 defaults 0 2" >> /etc/fstab
        ```

        * 这将确保您的分区在每次系统启动时自动挂载。

     5. 验证：

        ```bash
        df -h
        ```

        * 这将显示所有已挂载的分区，包括您的新分区。

2. Linux扩容磁盘

   * ```shell
     [root@dataserver ~]# fdisk -l
     
     Disk /dev/sda: 161.1 GB, 161061273600 bytes, 314572800 sectors
     Units = sectors of 1 * 512 = 512 bytes
     Sector size (logical/physical): 512 bytes / 512 bytes
     I/O size (minimum/optimal): 512 bytes / 512 bytes
     Disk label type: dos
     Disk identifier: 0x00037669
     
        Device Boot      Start         End      Blocks   Id  System
     /dev/sda1   *        2048     2099199     1048576   83  Linux
     /dev/sda2         2099200   209715199   103808000   8e  Linux LVM
     
     Disk /dev/mapper/centos-root: 53.7 GB, 53687091200 bytes, 104857600 sectors
     Units = sectors of 1 * 512 = 512 bytes
     Sector size (logical/physical): 512 bytes / 512 bytes
     I/O size (minimum/optimal): 512 bytes / 512 bytes
     
     
     Disk /dev/mapper/centos-swap: 8455 MB, 8455716864 bytes, 16515072 sectors
     Units = sectors of 1 * 512 = 512 bytes
     Sector size (logical/physical): 512 bytes / 512 bytes
     I/O size (minimum/optimal): 512 bytes / 512 bytes
     
     
     Disk /dev/mapper/centos-home: 44.1 GB, 44149243904 bytes, 86228992 sectors
     Units = sectors of 1 * 512 = 512 bytes
     Sector size (logical/physical): 512 bytes / 512 bytes
     I/O size (minimum/optimal): 512 bytes / 512 bytes
     
     ```

   * > 解读 `fdisk -l` 命令输出
     >
     > 您的另一台服务器的磁盘信息如下：
     >
     > **磁盘 /dev/sda：**
     >
     > * **大小：** 161.1 GB
     > * **总扇区数：** 314572800
     > * **单位：** 每扇区 512 字节
     > * **扇区大小：** 512 字节
     > * **I/O 大小：** 512 字节
     > * **磁盘标签类型：** dos
     > * **磁盘标识符：** 0x00037669
     > * **分区：**
     >     * **`/dev/sda1`：**
     >         * 启动标志：`*`（活动）
     >         * 起始扇区：2048
     >         * 结束扇区：2099199
     >         * 大小：1048576 扇区
     >         * ID：83（Linux）
     >         * 系统：Linux
     >     * **`/dev/sda2`：**
     >         * 起始扇区：2099200
     >         * 结束扇区：209715199
     >         * 大小：103808000 扇区
     >         * ID：8e（Linux LVM）
     >         * 系统：Linux LVM
     >
     > **磁盘 /dev/mapper/centos-root：**
     >
     > * **大小：** 53.7 GB
     > * **总扇区数：** 104857600
     > * **单位：** 每扇区 512 字节
     > * **扇区大小：** 512 字节
     > * **I/O 大小：** 512 字节
     >
     > **磁盘 /dev/mapper/centos-swap：**
     >
     > * **大小：** 8455 MB
     > * **总扇区数：** 16515072
     > * **单位：** 每扇区 512 字节
     > * **扇区大小：** 512 字节
     > * **I/O 大小：** 512 字节
     >
     > **磁盘 /dev/mapper/centos-home：**
     >
     > * **大小：** 44.1 GB
     > * **总扇区数：** 86228992
     > * **单位：** 每扇区 512 字节
     > * **扇区大小：** 512 字节
     > * **I/O 大小：** 512 字节
     >
     > 总结
     >
     > 这台服务器的磁盘配置如下：
     >
     > * 一个 161.1 GB 的磁盘 (`/dev/sda`)，分为两个分区：
     >     * `/dev/sda1`：一个 1 GB 的 Linux 分区，用于引导系统。
     >     * `/dev/sda2`：一个 103.8 GB 的 Linux LVM 分区，用于存储数据。
     > * 三个逻辑卷：
     >     * `/dev/mapper/centos-root`：一个 53.7 GB 的逻辑卷，用于存储根文件系统。
     >     * `/dev/mapper/centos-swap`：一个 8.5 GB 的逻辑卷，用于交换空间。
     >     * `/dev/mapper/centos-home`：一个 44.1 GB 的逻辑卷，用于存储用户家目录。
     >
     > 这台服务器的磁盘空间充足，可以满足您的需求。

   * ```shell
      ## 解读磁盘空间分配情况
      
      根据您的 `fdisk -l` 命令输出，可以看出这台服务器的 161.1GB 磁盘已被完全分配。
      
      * 其中 1GB 用作 `/dev/sda1` 分区，用于引导系统。
      * 剩余的 160.1GB 用作 `/dev/sda2` 分区，用于 Linux LVM。
      
      **LVM（Logical Volume Management，逻辑卷管理）**是一种用于管理磁盘空间的工具。它允许您将多个物理磁盘合并成一个虚拟的磁盘池，然后将该磁盘池划分为多个逻辑卷。
      
      从您的输出中可以看出，该服务器的 `/dev/sda2` 分区被用于创建三个逻辑卷：
      
      * `/dev/mapper/centos-root`：53.7GB，用于存储根文件系统。
      * `/dev/mapper/centos-swap`：8.5GB，用于交换空间。
      * `/dev/mapper/centos-home`：44.1GB，用于存储用户家目录。
      
      这三个逻辑卷总共使用了 106.3GB 的空间，剩余 53.8GB 的空间未被分配。
      
      **因此，您是对的，这台服务器的 161.1GB 磁盘还存在未进行分配的空间，大约为 53.8GB。**
      
      **关于如何使用这部分未分配的空间，您可以选择：**
      
      * 将其格式化为一个新的分区，并将其挂载到一个目录，用于存储数据。
      * 将其添加到现有的 LVM 逻辑卷中，以增加其容量。
      
      **需要注意的是，在进行任何操作之前，您需要备份您的数据，以免造成数据的丢失。**
      ```

   * **1. 将其格式化为一个新的分区，并将其挂载到一个目录，用于存储数据。**

      **步骤：**

      - 使用 `fdisk` 命令创建新的分区。

      - 格式化新分区。

      - 将新分区挂载到一个目录。

      - ```shell
        # 创建一个新的分区
        fdisk /dev/sda
        
        # 选择分区 2
        n
        p
        2
        
        # 使用默认值
        +
        w
        
        # 格式化新分区
        mkfs.ext4 /dev/sda2
        
        # 挂载新分区到 /data 目录
        mkdir /data
        mount /dev/sda2 /data
        ```

   * **2. 将其添加到现有的 LVM 逻辑卷中，以增加其容量。**

     **步骤：**

     - 使用 `pvcreate` 命令将未分配空间添加到物理卷组中。

     - 使用 `lvextend` 命令将物理卷添加到现有的逻辑卷中。

     - 使用 `resize2fs` 命令扩展文件系统。

     - ```shell
       # 将未分配空间添加到物理卷组
       pvcreate /dev/sda2
       
       # 将物理卷添加到现有的逻辑卷
       lvextend -l +100%FREE /dev/mapper/centos-home
       
       # 扩展文件系统
       resize2fs /dev/mapper/centos-home
       ```

   * **3.为了给 `/dev/mapper/centos-root` 扩容，可以按照以下步骤操作：**

      **步骤：**

      * **增加物理卷**:
         1. 使用 `fdisk` 增加新的分区。
         2. 将新的分区标记为 LVM 类型。

      * **扩展物理卷组**:
         1. 使用 `pvcreate` 初始化新的分区为物理卷。
         2. 使用 `vgextend` 将新的物理卷添加到现有的卷组。

      * **扩展逻辑卷**:
         1. 使用 `lvextend` 扩展逻辑卷。
         2. 使用 `resize2fs` 或 `xfs_growfs` 扩展文件系统。

      具体步骤如下：

      ### 1. 增加物理卷

      首先使用 `fdisk` 来创建新的分区：

      ```bash
      fdisk /dev/sda
      ```

      在 `fdisk` 交互模式中：

      - 输入 `n` 创建新分区。
      - 输入 `p` 选择主分区。
      - 输入分区号（一般是 3，如果已有 /dev/sda1 和 /dev/sda2）。
      - 使用默认的起始扇区（直接按 Enter）。
      - 使用默认的结束扇区（直接按 Enter）。
      - 输入 `t` 改变分区类型。
      - 输入新分区号。
      - 输入 `8e` 将新分区类型设为 LVM。
      - 输入 `w` 写入分区表并退出。

      重新扫描分区表：

      ```bash
      partprobe /dev/sda
      ```

      ### 2. 扩展物理卷组

      创建新的物理卷：

      ```bash
      pvcreate /dev/sda3
      ```

      将新的物理卷添加到现有的卷组（假设卷组名称为 `centos`）：

      ```bash
      vgextend centos /dev/sda3
      ```

      ### 3. 扩展逻辑卷

      扩展逻辑卷（假设逻辑卷名称为 `root`）：

      ```bash
      lvextend -l +100%FREE /dev/centos/root
      ```

      ### 4. 扩展文件系统

      可以通过多种方法查看文件系统的类型。以下是几种常用的方法：

      ```bash
      df -T # df 命令可以显示文件系统的类型及其使用情况。使用 -T 选项可以显示文件系统的类型。
      lsblk -f # lsblk 命令也可以显示块设备的信息，包括文件系统类型。
      blkid # blkid 命令可以显示所有块设备及其文件系统类型。
      ```

      最后，根据你使用的文件系统类型，扩展文件系统：

      如果是 `ext4` 文件系统：

      ```bash
      resize2fs /dev/centos/root
      ```

      如果是 `xfs` 文件系统：

      ```bash
      xfs_growfs /dev/centos/root
      ```

      完成后，你可以检查文件系统的大小是否已扩展：

      ```bash
      df -h
      ```

      这些步骤完成后，你的 `/dev/mapper/centos-root` 逻辑卷和文件系统应该会扩展到使用新的 10GB 空间。

   * **4.要将现有的 `/dev/sda2` 分区扩展到新的空间，可以按照以下步骤操作。请注意，这样做有一定风险，建议在操作前备份数据。**

      1. **删除并重新创建分区**:
         - 先删除 `/dev/sda2` 分区（注意这不会删除数据）。
         - 重新创建分区，覆盖原来的起始位置，但终点扩展到新的磁盘末尾。

      2. **扩展物理卷**:
         - 将物理卷扩展到新的分区。

      3. **扩展逻辑卷和文件系统**:
         - 扩展逻辑卷。
         - 扩展文件系统。

      具体步骤如下：

      ### 1. 删除并重新创建分区

      使用 `fdisk` 操作磁盘：

      ```bash
      fdisk /dev/sda
      ```

      在 `fdisk` 交互模式中：

      - 输入 `d` 删除分区。
      - 输入 `2` 选择要删除的分区号 `/dev/sda2`。
      - 输入 `n` 创建新分区。
      - 输入 `p` 选择主分区。
      - 输入分区号 `2`。
      - 输入起始扇区，默认值应与删除的分区相同（直接按 Enter）。
      - 使用默认的结束扇区或输入新的结束扇区（直接按 Enter 扩展到磁盘末尾）。
      - 输入 `t` 改变分区类型。
      - 输入 `2` 选择分区号。
      - 输入 `8e` 将分区类型设为 LVM。
      - 输入 `w` 写入分区表并退出。

      重新扫描分区表：

      ```bash
      partprobe /dev/sda
      ```

      ### 2. 扩展物理卷

      扩展物理卷：

      ```bash
      pvresize /dev/sda2
      ```

      ### 3. 扩展逻辑卷和文件系统

      扩展逻辑卷（假设逻辑卷名称为 `root`）：

      ```bash
      lvextend -l +100%FREE /dev/centos/root
      ```

      扩展文件系统：

      如果是 `ext4` 文件系统：

      ```bash
      resize2fs /dev/centos/root
      ```

      如果是 `xfs` 文件系统：

      ```bash
      xfs_growfs /dev/centos/root
      ```

      完成后，检查文件系统的大小是否已扩展：

      ```bash
      df -h
      ```

      这些步骤完成后，你的 `/dev/mapper/centos-root` 逻辑卷和文件系统应该会扩展到使用新的磁盘空间。请务必在操作前备份重要数据，确保数据安全。

3. 国源的服务器

   * 开发服务器：10.90.12.192
     * 用户：root
     * 密码：jiangfl@123
   * 数据服务器：10.90.12.199 
     * 用户：root
     * 密码：root@199
   * 单体服务器：10.90.12.208
     * 用户：root
     * 密码：test88891715.

## 5.28 周二 晴

### TODO：

1. 禅道-9138 登记管理/核对列表/核对页面，《既往史》tab页记入核对任务完成的条件

## 5.29 周三 晴

### TODO：

1. 继续禅道-9138
1. 10.90.12.208服务器样本库存储版运维-北京、东营、cdc重新启动
1. 禅道-9147 资产管理-仪器设备使用记录菜单，仪器使用页面用途和状态两列小一点，把开始时间和结束时间完全显示出来。使用人员修改为显示真名不要工号

## 5.30 周四 晴

### TODO：

1. 禅道-9157 资产管理-仪器设备信息管理菜单，分页查询列表最后添加【关联容器】列，字段为freezerId，将该字段通过关联表或代码处理的方式添加一个freezerName字段显示为中文
1. 存储管理-转移列表-导出样本信息-历史位编码，线上调试分析bug，找到问题sql
1. 禅道-9099 制备分装页面-批量删除分装后样本时，如果底码不为空时添加提示，防止批量删除时错误的勾选了已经填了底码的样本【暂时不做，评审完毕之后添加】
1. 医院下班后进行邵逸夫版本更新

## 5.31 周五 晴

### TODO：

1.  春松客服：开源客服系统https://gitee.com/cskefu/cskefu

   ![image-20240531091401076](.\2024.assets\image-20240531091401076.png)



